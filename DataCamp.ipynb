{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"page-header\"><h1 class=\"alert alert-info\">Data Camp: Stock Prediction<br/>\n",
    "<small>Gustavo Castro, Lucas Furquim, Francisco Ribeiro, Alvaro Serra<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-success\">Introduction</h1>\n",
    "\n",
    "Managing and creating good <a href = \"http://www.investopedia.com/terms/p/portfoliomanagement.asp\"> portfolios </a> are main works in the financial world, specially at the Quantitative Asset Management sector. In this context, one needs to decide which portfolio allocation will give the best future return.\n",
    "\n",
    "<img src=\"Image/SP500.jpg\">\n",
    "\n",
    "To do so, it is vital to be able to forecast some stock behaviors and their variances. For more detailed information and explanation please refer to: <a href = \"http://pubsonline.informs.org/doi/abs/10.1287/mnsc.2013.1838\" > Risk Premium \n",
    "forecast </a> and <a href =\"http://cims.nyu.edu/~almgren/timeseries/Vol_Forecast1.pdf\"> GARCH Model </a>.\n",
    "\n",
    "The goal of this challenge is to predict the <a href = \"http://www.investopedia.com/terms/s/sp500.asp\"> SP500 index </a>  behavior using some market data and to mine the different interactions this index might have with the proposed features.\n",
    "\n",
    "Other sources of information and data include <a href = \"https://www.bloomberg.com/markets/stocks\"> Bloomberg </a> and <a href = \"http://finance.yahoo.com/\"> Yahoo Finance </a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-success\"> Prediction task</h1>\n",
    "\n",
    "The goal is to predict the index values for the year of 2015. To do so, a historical data of more than a hundred years is offered.\n",
    "\n",
    "<img src=\"Image/indXtime.png\">\n",
    "\n",
    "The student is completly free to define his predicton model and the time interval that will be considered to calibrate it. \n",
    "\n",
    "As always in the machine learning context, we accentuate the importance of a proper feature analysis, their relevances, signifcations and impacts under this prediction context. To stimulate this work, we propose, at the Data section of this notebook, the use of some new features and we strongly advice the wise choice of the features' relevances and the creation of others that the student may find relevant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-success\"> Imports and Initial Setup </h1>\n",
    "\n",
    "## Tools & Setup\n",
    "\n",
    "- *The simple way*: Install the Anaconda python distribution https://www.continuum.io/downloads\n",
    "- *The fine-grained way:* Install each of the following tools\n",
    "    - Python\n",
    "    - Jupyter\n",
    "    - Scikit-learn\n",
    "    - Pandas\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-success\"> Data </h1>\n",
    "\n",
    "A dataset of the monthly values of the SP500 index since january 1871 until december 2015 is proposed. A detailed explanation is given below.\n",
    "\n",
    "It is also important to be aware of the existence of NaN values in the database, specially in older periods (before 1900). We thus strongly suggest that the student initially ignores the data older than january 1950 to avoid initial problems with database empty and NaN cells. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-success\">Data description</h1>\n",
    "\n",
    "The following table contains the description of the different fields in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_brute = pd.read_csv('Data/BruteMetaData.csv')\n",
    "meta_brute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_brute = pd.read_csv('Data/BruteTrainData.csv')\n",
    "train_brute.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_brute.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_brute.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out that the following treated database can also be very useful\n",
    "\n",
    "The following table contains the description of the different columns in the treated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_treated = pd.read_csv('Data/TreatedMetaData.csv')\n",
    "meta_treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_treated = pd.read_csv('Data/TreatedTrainData.csv')\n",
    "train_treated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_treated.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_treated.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-success\">The prediction model</h1>\n",
    "\n",
    "We are going to follow the scikit-learn API specs in order to define a `FeatureExtractor` and a `Regressor`.\n",
    "\n",
    "## The feature extractor\n",
    "\n",
    "In <code>feature_extractor.py</code> you will define a class called <code>FeatureExtractor</code>. Its main <code>transform</code> method takes a pandas <b>DataFrame</b> and outputs a <b>numpy array</b>.\n",
    "\n",
    "- The `FeatureExtractor` inherits from `TransformerMixin`.\n",
    "- It implements a `fit` (optional) and a `transform` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class FeatureExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_df['yyyymm'] -= X_df['yyyymm'][0]\n",
    "        X_df['yyyymm'] /= X_df['yyyymm'].iat[-1]\n",
    "        return X_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The regressor\n",
    "\n",
    "- The `Regressor` inherits from `BaseEstimator`,\n",
    "- The `__init__()` function initiates all of the arguments and configurations. \n",
    "- The regressor must implement a `fit()` and  a `predict()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "class Regressor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.reg = make_pipeline(\n",
    "            Imputer(strategy='median'),\n",
    "            ExtraTreesRegressor(n_estimators=10))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self.reg.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.reg.predict(X)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit testing\n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. For this we\n",
    "provide a unit test. Place the python file <code>regressor.py</code>, the data <code>public_train.csv</code>, and the \n",
    "<code>user_test_submission.py</code></a> in a directory and run \n",
    "\n",
    "<code>python user_test_submission.py</code>\n",
    "\n",
    "If it runs and prints \n",
    "<code>\n",
    "rmse =  [some_number]\n",
    "rmse =  [some_number]\n",
    "</code>\n",
    "you can submit the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python user_test_submission.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
